#+STARTUP: logdone
* May
** 13 [100%]
   - [X] Read Simix and section 3 of the paper
** 14 [100%]
   - [X] Revisit Orgmode emacs (no more vim orgmode)
   - [X] Revisit Tutorials, deploy,platform, play w/code
   - [X] Read Simix code, try to understand the main parts of it.
** 15 [100%]
   - [X] understand how to run experiment.
** 16 [100%]
   - [X] Figure out how to get the times of the previous exp. (system time, in log folder)
   - [X] deploy a parapluie node in rennes. Somehow it refuses to give me a node there, so I got a parapide node. Its not the same, but at least I am able to run the simulation.
   - [X] Install newer version of simgrid. I struggled a lot here, since it seems there are some files missing in examples/msg/chord/ and examples/platform/
   - [X] Figure out how to run with different ammount of threads --cfg flag for simgrid simulations


** 19 [100%]
   - [X] Figure out how to run all the experiments using a script
   - [X] Schedule a Launch with all the experiments. Run in parapluie-9.rennes.grid5000.fr

** 20 [100%] 
   - [X] Run simulation in G5K, using the last version available of [[https://gforge.inria.fr/projects/simgrid/][simgrid]]
	 Anyway, the simulation was too slow, couldnt finish it. Had some unexpected exceptions too.

** 21 [100%]
   - [X] Run te experiment available at revision 918d6192, but with the newer revision. NOTE: this didnt work, the script to run the experiment is simpler than the one I actually need
   - [X] Run modified script on the older version and see what happens
   - [X] Run the scripts of 2011_parallel on the older version and see what happens
   - [X] Run the scripts of 2011_parallel on the newer version and see what happens. Still slower than the paper, at least in constant sequential mode.
** 22 [100%] Simulation is slow, even with the same parameters (like the older version). 
   - [X] Try with other runtime options, lile --cfg=config
   - [X] Try to figure out what the bottleneck is
   - [X] Learn to use FlameGraph
** 23 [100%]
   - [X] read and write down simix things
   - [X] try to use perf to understand performance ussues

     
** 26 [100%]
   - [X] Read and write down things about thread synchronization.
** 27 [100%]
   - [X] profilers: poor man profiler, perf, gprof.
   - [X] learn about thread synchronization.

** 28 [100%]
   - [X] Profiling to find bottleneck in simulation (poorman's, perf, gprof, flamegraph)
    
* June
** 2 - 6 SUD'14

** 10 [100%]
   - [X] Make script to test performance on different versions.
   - [X] Start tests performance in different versions of SG, using a "bisection" methodology.

To run (old) performance regression test: ./SGXP.pl --site=nancy --cluster=graphene --test=chord,goal --rev="e32a2a561ef184dc9ef8cdaf25759bba6b2ea198,71c9241aa27344f9f8f02f3c1272af4556691713,f95108e7e5bcb66bba76a24c1c433eee710e38e0"
** 11 [100%]
   - [X] Start with optimization of dynamic threshold of paper, have an initial version working (not necessarily more efficient).
** 12 [100%]
   - [X] Performances timings of dynamic threshold algorithm.
** 13 [100%]
   - [X] Run performance regression test.
   - [X] Finish performance timings of dynamic threshold algorithm, check if it is really working. Plot a graph.
   - [X] Try to start with the cores optimization of parmap.


** 16 [100%]
   - [X] Re run Performance regression test with fixed amount of commits. For version 3.9 and ahead there are ~2221 commits (until 3.11 release, +2270 until HEAD)
** 17 [100%]
   - [X] Debug dynamic threshold algorithm
** 18 [100%]
*** DONE make a Rstudio file [100%]
  CLOSED: [2014-06-18 Wed 13:57]
**** DONE Transcript paper schema into file
     CLOSED: [2014-06-18 Wed 17:02]
**** DONE graph (Gnuplot to R)
     CLOSED: [2014-06-18 Wed 17:02]
** 19 [100%]
*** DONE start with pinpoint test
    CLOSED: [2014-06-20 Fri 09:30]
** 20 [100%]
*** DONE Fast performance tests to pinpoint the faulty commit & fix it. [66%]
    CLOSED: [2014-06-24 Tue 09:25]
**** DONE Adapt script to do it
   CLOSED: [2014-06-18 Wed 17:01]
**** DONE Run it in a dicotomy way: first the last commit, then some older commit, then a commit in the middle... until find the faulty one.
   CLOSED: [2014-06-20 Fri 17:21]
     Faulty commits-> well, actually I think there are dozens at least, since the performance drops down with the inclusion of "surf++"


** 23 [100%]
*** DONE start with pinpointing of surf branch
    CLOSED: [2014-06-24 Tue 09:26]
** 24 [100%]
**** DONE Explore logs of execution of C/C++ versions. Explore surf layer, searching for bug, using Paul suggestions.
     CLOSED: [2014-06-25 Wed 09:55]
** 25 [100%]
   - [X] Keep digging in branches. Special atention to hypervisor one
** 27 [100%]
*** DONE Apparently, the perforance drop was introduced in smx_network:1195 (compare with an older commit). make 2 tests: one with the code similar to the older version, one with the if blocks "right". 
    CLOSED: [2014-06-27 Fri 17:29]
    

** 30 [100%]
  - [X] Prepare scripts and code for experiments.

* July
** 1 [100%]
*** DONE Prepare code to run Amdahl Benchmark. Dont forget to set log_critical to the final print of Amdahl law. Then run exp. the same way without amdahl benchmark. In the table will be the final times, in the logs will be the times of the parallel/sequential execution too.
    CLOSED: [2014-07-01 Tue 16:00]
** 2 [100%]
*** DONE Run portion of experiments (<10k)
    CLOSED: [2014-07-02 Wed 17:56]
**** DONE without amdahl benchmark
     CLOSED: [2014-07-01 Tue 16:03]
**** DONE with amdahl benchmark
     CLOSED: [2014-07-02 Wed 17:55]
** 3 [100%]
- [X] benchmark experiment for SR. Still not working.
** 4 [100%]
*** DONE fix exp. of benchmark per SR.
    CLOSED: [2014-07-04 Fri 16:47]


** 7 [100%]
   - [X] plot, Rstudio, organize data
** 8 [100%]
*** DONE work on Amdahl section on Rstudio.
    CLOSED: [2014-07-08 Tue 15:30]
**** DONE from the logs, get sequential and parallel times (python)
    CLOSED: [2014-07-08 Tue 15:28]
**** DONE From the normal logs, get completely sequential times (user+system)(python)
     CLOSED: [2014-07-08 Tue 16:21]
** 9 [100%]
*** DONE work on Rstudio
    CLOSED: [2014-07-10 Thu 10:57]
** 10 [100%]
*** DONE get better data and plot 2nd graph of intro.
    CLOSED: [2014-07-11 Fri 11:22]
** 11 [100%]
*** DONE run sr experiment with more nodes and gather data. The plot is still weird.
    CLOSED: [2014-07-15 Tue 09:50]


** 15 [100%]
*** DONE keep working on SR round times plot
    CLOSED: [2014-07-17 Thu 09:41]
**** DONE make more experiments from the laptop
     CLOSED: [2014-07-17 Thu 09:41]
** 16 [100%]
   - [X] valgrind and gdb to track the bug in chord. Found a corruption in memory, still dont find the bug
** 17-18 [100%]
   - [X] Analyze stacks, the bug has its origins on the SR benchmarks


** 21 [100%]
   - [X] Using gdb. Found where the SIGSEV comes from: raw_swapcontext from suspend_serial of smx_context_raw.c. The problem is with the address of the next_context
     The problem seems to be with the way 'i' index was computed in smx_ctx_raw_suspend_serial. I fixed it and now it works.
** 22 [100%]
   - [X] Found 2 more segfaults: when nthreads=1 using the SR benchmarks, and when the sizes are too big (with or without benchmarks) in chord simulation.
   - [X] Re run experiments with SR with smaller sizes, in the cluster
** 23 
   - found that the 'performance fix' might be what causes the segfaults in some scenarios 
** 24 
   - Fixed potential SIGSEV when removing communication action when a SURF communication action is finishes (SIMIX_post_comm)
** 25 [100%]
   - [X] Make new experiments with bigger sizes: speedup (amdahl, /log_amdahl), SR (/log_sr), and raw (/log)(to compare intrusiveness of experiment). Use parapluie
   - [X] Prepare "micro" amdahl timings. That would be I)c). Use SR experiment, one with 1 thread (seq), one with better parallel version. Average timings of each amount of processes and then calculate speedup of each amount of processes


** 28 [100%]
   - [X] run SR like this: adding all the times of the parallel execution; taking the maxtime of the parallel execution. That way I get the sequential time of each SR, and the parallel time. 
   - [X] generate 300000, 1000000 nodes files again, there are some problems with the current ones. Run final part of experiments with it(raw, amdahl, sr)
   - [X] Migrate from Rstudio to emacs
** 29 [100%]
   - [X] Work on better plots in rstudio. Work on report
** 30 [100%]
   - [X] fix SR
   - [X] keep working with report
** 31 [100%]
   - [X] organize data of experiments. Check that I have everything and probably relaunch some exp. to update data with the fixed version of SimGrid

* August
** 1 [100%]
   - [X] work on benchmark not intrusive
** 4 [100%]
   - [X] make new speedup plot with the bigger sizes (already got the logs). with 2,4,8,16,24 threads
   - [X] put numbers below bars in sr-distribution
** 5 [100%]
   - [X] get new data and make a decent sr-times plot,
   - [X] make sr-par-threshold with dots and add smooth line.
** 6 [100%]
   - [X] Start with optimizations of parmap.
** 7 [100%]
   - [X] Finish with binding cores details.
   - [X] Do some benchmarks with that.
   - [X] Write section in report, plot a graph
** 8 [100%]
   - [X] Check cache misses of previous/optimized version with perf.
   - [X] Start with parmap between N cores.
** 11 [100%]
   - [X] find why I get a deadlock running chord -> commit b533e2f7a6f6ebf750a96243804688169d2e6d9e, change only the #define. Also, check that the code at SIMIX_post_comm is deleted.
** 12 [100%]
   - [X] Still have some random deadlocks at the end of the simulation.Random. have to do some pinpoint, beginning from the performance fix.
** 13 [100%]
   - [X] Fix deadlock: delete SIMIX_process_cleanup(smx_proc) from src/msg/msg_process.c, why is that there?
   - [X] Do timings with maestro sleep+(N-1)
 
** 14 [100%]
   - [X] Timings maestrosleeps + (N-1) with 100k, 300k
** 18 [100%]
   - [X] Put code of bindings in order.
   - [X] Exp. intrusiveness with 3k, 5k, 10k, 25k, 50k, 75k nodes. (in progress)
** 19 [100%]
   - [X] Work with ideas of adaptative algorithm. Do some meditions if have time.
   - [X] Tons of meditions and benchmarks of parmap opt., intrusiveness, amdahl speedup.

** 20 [100%]
   - [X] Amdahl speedup with 300k, 500k
   - [X] Short tests with adaptive algorithm in cluster.
   - [X] graph to show times of parmapN, parmapN-1 and original (al)
   - [X] Polish some things in report, like the plots with newer data, and some numbers using that data.
** 21 [100%]
   - [X] Write down things about binding threads.
   - [X] Run a new benchmark with the adaptive algorithm
** 22 [100%]
   - [X] Significant improve on adaptive algorithm plot. Write conclusions of this.
   - [X] Run remaining Amdahl experiments.
** 25 [%]
   - [ ] Try a plot Constant vs. Precise with sr-par-threshold plot.
   - [ ] Start busy waiters optimization.

   - [ ] Correr SR en paralelo bien, (fijarse si el secuencial tambien necesita)
  HOW TO SCHEDULE A SIMULATION FOR A NIGHT, A WEEKEND
   - [ ] make tests with 500000, 1000000 nodes (schedule for a night, weekend).
* TODO Experiment of Section I [0%]
** TODO Benchmark: before Amdahl benchmark, do experiments with the optimized version without benchmark and save those timings. Thats is for the comparation of timings to say that our benchmark is not intrusive.
*** DONE modify scripts for this.
    CLOSED: [2014-06-30 Mon 15:34]
** TODO Gather data-> id Sched Round : time taken by each SR : #proc. From this data set I can generate the 2 graphs:
*** DONE Find the ifndef/define of the benchmarks that are already done
    CLOSED: [2014-07-02 Wed 09:29]
*** DONE Set up everything to run tests and gather data (with chord, for example)
    CLOSED: [2014-07-07 Mon 13:13]
**** DONE Fix code on SR benchmarks.
     CLOSED: [2014-07-07 Mon 13:13]
*** DONE The graph 1: Y=% of scheduling rounds taking #proc. x=#proc
    CLOSED: [2014-07-08 Tue 09:30]
*** DONE The graph 2: Y=number of scheduling round. x=Time (is the time of each scheduling round).
    CLOSED: [2014-07-25 Fri 10:58]
** TODO Amdhal: Optimal Ahmdal threshold: measure time of sequential executions, then measure time of parallel+sequential execution in a parallel execution. Calculate Amdahl law.
*** TODO try with other examples.



* Useful info:
** To run classical chord experiment
   - Steps to connect to G5K and deploy SimGrid:
     1) connect to G5k, connect to Rennes, try to ask a parapluie node:
       oarsub -p "cluster='parapluie'" -l nodes=5,walltime=2 -I -t deploy
	Aks for an specific node, for example:
       oarsub -p 'cluster="parapide"' -l {'network_address in ("parapide-8.rennes.grid5000.fr")'}/nodes=1,walltime=5:00 -I -t deploy
     2) apt-get update && apt-get install cmake make gcc git libboost-dev libgct++ libpcre3-dev linux-tools gdb liblua5.1-0-dev libdwarf-dev libunwind7-dev valgrind libsigc++
     3) copy simgrid from Rennes frontend
     4) cmake -Denable_compile_optimizations=ON -Denable_supernovae=OFF -Denable_compile_warnings=OFF -Denable_debug=OFF -Denable_gtnets=OFF -Denable_jedule=OFF -Denable_latency_bound_tracking=OFF -Denable_lua=OFF -Denable_model-checking=OFF -Denable_smpi=OFF -Denable_tracing=OFF -Denable_documentation=OFF .
     5) make && make install && sudo chmod 777 /usr/local/lib/libsimgrid.so.<version_number>
     6) example run:
        ./chord One_cluster_nobb_1000_hosts.xml chord1000.xml --log=root.thres:critical --cfg=contexts/stack_size:16 --cfg=contexts/guard_size:0 --cfg=network/model:Constant --cfg=network/latency_factor:0.1
	./chord One_cluster_nobb_10000_hosts.xml chord10000.xml --cfg=contexts/stack_size:16 --log=root.thres:critical --cfg=network/model:Constant --cfg=network/latency_factor:0.1 --cfg=contexts/nthreads:4
	./chord One_cluster_nobb_10000_hosts.xml chord10000.xml --cfg=contexts/stack_size:16 --log=root.thres:critical --cfg=maxmin/precision:0.00001 --cfg=contexts/nthreads:4 --cfg=maxmin/precision:0.00001
     7) to run test, this should work:  ./testall.sh path/to/simgrid/ 3.11
     8) Dont forget to modify script to copy logs to home folder (otherwise they will lay on the node, and they will be erased)
     9) To copy something from rennes to the deployed node: scp -r rtortilopez@rennes.grid5000.fr:path/to/file . 
   - To print current revision hash git rev-parse --short HEAD
     1) git log --pretty=oneline --pretty=format:"%h %s"  --since 17/11/2013 --until 23/01/2014 |  less
     2) If it fails to allocate stack with big amount of nodes, then use --cfg=contexts/guard_size:0

for file in sr_*; do tail -n +0 $file >> sr_total_1000.log; done
** Profilers:
    1) perf record ./chord ...
    2) perf record -g -e cpu-clock ./chord and then:
    3) perf script | stackcollapse-perf.pl | flamegraph.pl > myapp.svg
    4) script gdb poorman profiler of Gabriel | stackcollapse-gdb.pl | flamegraph.pl > myapp.svg . Example:
       Run chord:
       ./chord One_cluster_nobb_10000_hosts.xml chord10000.xml --log=root.thres:critical --cfg=contexts/stack_size:16 --cfg=network/model:Constant --cfg=network/latency_factor:0.1 &
       and: 
       ./poorman.sh 1000 0.1 $(pidof chord) | ./stackcollapse-gdb.pl | ./flamegraph.pl > myapp.svg
    5) To copy from node to laptop: scp root@<node_number>.rennes.grid:~/SimGrid/examples/msg/chord/myapp.svg .
    6) poor man's profiler
    7) try with compilation flag -fno-omit-frame-pointer
** To run SG-PRT (Performance regression test):
repository: git+ssh://rtortilo@scm.gforge.inria.fr//gitroot/simgrid/simgrid-perf-reg-tests.git
1) set up a node somewhere.
2) apt-get update && apt-get install cmake make gcc git libboost-dev libgct++ libpcre3-dev linux-tools gdb r-base ruby gem . If possible, gem install rserve-client
3) To install libraries of R, use script download_r_packages.sh
4) Start Rserve daemon in R (library(Rserve); Rserve())
5) set number of commits wanted to analyze in SG-PRT.rb
6) ./SG-PRT.rb

** Pinpoint tests
1) To get a list of specific commits (and count them,etc) git log 772d63c..ce1289d --pretty=oneline | head -n570 | less 
2) If compilaton of chord fails for version 3.10 (or whatever else), try copying the content of folder src/ to usr/local/src
* Paper
** Problem Analysis
  1) Optimal threshold for Amdhal. Which portion of the problem is paralellizable. Which not. Why is hard?(a)
     Two graphics: #SD vs. #process (b) && #SD vs. time(SD) (c)
     
** Find threshold between sequential/parallel
  1) test over real runs. not simulations (what would be real runs?)
  2) geometric mean (of..)
Once I get the basis threshold:
  3) adaptative algorithm to choose how many threads wake up in each round:
     This is what is already done (smx_ctx_*_runall):
        * if #proc<threshold  --> sequential
        * elif #proc>threshold  --> parallel
     Change threshold dinamically:
     There are timers already defined in the code, but they are not used to do this:
     * if #proc<thresh -->  sequential exec. (chrono) and then seq_time += chrono; seq_amount += #proc;
     * else ------------->  parallel exec. (crhono) and then par_time+=chrono; par_amount+=#proc;
     After 5 sched round:
                (a)                     (b)
     * if seq_time/seq_amount > par_time/par_amount THEN --thresh (c - coeff x a/b)
     * else ++thres
  4) parallel threshold of parmap in cache?
  5) Fast Init: save threshold on disk?

Versions of SimGrid:
SimGrid3.11.1 e32a2a561ef184dc9ef8cdaf25759bba6b2ea198
SimGrid3.8    71c9241aa27344f9f8f02f3c1272af4556691713
SimGrid3.9    f95108e7e5bcb66bba76a24c1c433eee710e38e0
SimGrid3.10   772d63cca583f5d16096fa9f487b4ab07d9af8f0

** Optimizations
  1) bind each tread to one core [X]
  2) implement parmap between N cores: maestroawake+(N-1)(default); [X]
                                       The key for the next 2 optimizations relies on finding how to sleep master,
                                       the rest involves only creating N threads or N-1 threads:
                                           maestrosleep+(N)
                                           maestro sleep+(N-1)
  3) parmap next. Not now.
  4) Ask: busy waiters with different #proc. (1-5 --> sequential; 6-20 --> 4busy waiters; 20-inf --> 16 busy waiter).[X]
     Speedup is the same as parallel?
  Performance regression testing
  
** Hot topics task 5
1) we are near amdhal paralelism threshold, because there are no more things to paralellize.
2) we want to run in parallel not only the threads but also the events in each thread?
3) we want to find the independent events and run them in parallel.


