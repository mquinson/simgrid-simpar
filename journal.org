#+STARTUP: logdone
* May
** 13 [100%]
   - [X] Read Simix and section 3 of the paper
** 14 [100%]
   - [X] Revisit Orgmode emacs (no more vim orgmode)
   - [X] Revisit Tutorials, deploy,platform, play w/code
   - [X] Read Simix code, try to understand the main parts of it.
** 15 [100%]
   - [X] understand how to run experiment.
** 16 [100%]
   - [X] Figure out how to get the times of the previous exp. (system
     time, in log folder)
   - [X] deploy a parapluie node in rennes. Somehow it refuses to give
     me a node there, so I got a parapide node. Its not the same, but
     at least I am able to run the simulation.
   - [X] Install newer version of simgrid. I struggled a lot here,
     since it seems there are some files missing in
     examples/msg/chord/ and examples/platform/
   - [X] Figure out how to run with different ammount of threads --cfg
     flag for simgrid simulations

     
** 19 [100%]
   - [X] Figure out how to run all the experiments using a script
   - [X] Schedule a Launch with all the experiments. Run in
     parapluie-9.rennes.grid5000.fr

** 20 [100%] 
   - [X] Run simulation in G5K, using the last version available of
     [[https://gforge.inria.fr/projects/simgrid/][simgrid]] Anyway, the simulation was too slow, couldnt finish
     it. Had some unexpected exceptions too.

** 21 [100%]
   - [X] Run te experiment available at revision 918d6192, but with
     the newer revision. NOTE: this didnt work, the script to run the
     experiment is simpler than the one I actually need
   - [X] Run modified script on the older version and see what happens
   - [X] Run the scripts of 2011_parallel on the older version and see
     what happens
   - [X] Run the scripts of 2011_parallel on the newer version and see
     what happens. Still slower than the paper, at least in constant
     sequential mode.
** 22 [100%] Simulation is slow, even with the same parameters (like the older version). 
   - [X] Try with other runtime options, lile --cfg=config
   - [X] Try to figure out what the bottleneck is
   - [X] Learn to use FlameGraph
** 23 [100%]
   - [X] read and write down simix things
   - [X] try to use perf to understand performance ussues

     
** 26 [100%]
   - [X] Read and write down things about thread synchronization.
** 27 [100%]
   - [X] profilers: poor man profiler, perf, gprof.
   - [X] learn about thread synchronization.

** 28 [100%]
   - [X] Profiling to find bottleneck in simulation (poorman's, perf,
     gprof, flamegraph)
    
* June
** 2 - 6 SUD'14

** 10 [100%]
   - [X] Make script to test performance on different versions.
   - [X] Start tests performance in different versions of SG, using a
     "bisection" methodology.

To run (old) performance regression test: ./SGXP.pl --site=nancy
--cluster=graphene --test=chord,goal
--rev="e32a2a561ef184dc9ef8cdaf25759bba6b2ea198,71c9241aa27344f9f8f02f3c1272af4556691713,f95108e7e5bcb66bba76a24c1c433eee710e38e0"
** 11 [100%]
   - [X] Start with optimization of dynamic threshold of paper, have
     an initial version working (not necessarily more efficient).
** 12 [100%]
   - [X] Performances timings of dynamic threshold algorithm.
** 13 [100%]
   - [X] Run performance regression test.
   - [X] Finish performance timings of dynamic threshold algorithm,
     check if it is really working. Plot a graph.
   - [X] Try to start with the cores optimization of parmap.


** 16 [100%]
   - [X] Re run Performance regression test with fixed amount of
     commits. For version 3.9 and ahead there are ~2221 commits (until
     3.11 release, +2270 until HEAD)
** 17 [100%]
   - [X] Debug dynamic threshold algorithm
** 18 [100%]
*** DONE make a Rstudio file [100%]
  CLOSED: [2014-06-18 Wed 13:57]
**** DONE Transcript paper schema into file
     CLOSED: [2014-06-18 Wed 17:02]
**** DONE graph (Gnuplot to R)
     CLOSED: [2014-06-18 Wed 17:02]
** 19 [100%]
*** DONE start with pinpoint test
    CLOSED: [2014-06-20 Fri 09:30]
** 20 [100%]
*** DONE Fast performance tests to pinpoint the faulty commit & fix it. [66%]
    CLOSED: [2014-06-24 Tue 09:25]
**** DONE Adapt script to do it
   CLOSED: [2014-06-18 Wed 17:01]
**** DONE Run it in a dicotomy way: first the last commit, then some older commit, then a commit in the middle... until find the faulty one.
   CLOSED: [2014-06-20 Fri 17:21]
     Faulty commits-> well, actually I think there are dozens at least, since the performance drops down with the inclusion of "surf++"


** 23 [100%]
*** DONE start with pinpointing of surf branch
    CLOSED: [2014-06-24 Tue 09:26]
** 24 [100%]
**** DONE Explore logs of execution of C/C++ versions. Explore surf layer, searching for bug, using Paul suggestions.
     CLOSED: [2014-06-25 Wed 09:55]
** 25 [100%]
   - [X] Keep digging in branches. Special atention to hypervisor one
** 27 [100%]
*** DONE Apparently, the perforance drop was introduced in smx_network:1195 (compare with an older commit). make 2 tests: one with the code similar to the older version, one with the if blocks "right". 
    CLOSED: [2014-06-27 Fri 17:29]
    

** 30 [100%]
  - [X] Prepare scripts and code for experiments.

* July
** 1 [100%]
   - [X] Prepare code to run Amdahl Benchmark. Dont forget to set
     log_critical to the final print of Amdahl law. Then run exp. the
     same way without amdahl benchmark. In the table will be the final
     times, in the logs will be the times of the parallel/sequential
     execution too.
    CLOSED: [2014-07-01 Tue 16:00]
** 2 [100%]
*** DONE Run portion of experiments (<10k)
    CLOSED: [2014-07-02 Wed 17:56]
**** DONE without amdahl benchmark
     CLOSED: [2014-07-01 Tue 16:03]
**** DONE with amdahl benchmark
     CLOSED: [2014-07-02 Wed 17:55]
** 3 [100%]
   - [X] benchmark experiment for SR. Still not working.
** 4 [100%]
*** DONE fix exp. of benchmark per SR.
    CLOSED: [2014-07-04 Fri 16:47]


** 7 [100%]
   - [X] plot, Rstudio, organize data
** 8 [100%]
*** DONE work on Amdahl section on Rstudio.
    CLOSED: [2014-07-08 Tue 15:30]
**** DONE from the logs, get sequential and parallel times (python)
    CLOSED: [2014-07-08 Tue 15:28]
**** DONE From the normal logs, get completely sequential times (user+system)(python)
     CLOSED: [2014-07-08 Tue 16:21]
** 9 [100%]
*** DONE work on Rstudio
    CLOSED: [2014-07-10 Thu 10:57]
** 10 [100%]
*** DONE get better data and plot 2nd graph of intro.
    CLOSED: [2014-07-11 Fri 11:22]
** 11 [100%]
*** DONE run sr experiment with more nodes and gather data. The plot is still weird.
    CLOSED: [2014-07-15 Tue 09:50]


** 15 [100%]
*** DONE keep working on SR round times plot
    CLOSED: [2014-07-17 Thu 09:41]
**** DONE make more experiments from the laptop
     CLOSED: [2014-07-17 Thu 09:41]
** 16 [100%]
   - [X] valgrind and gdb to track the bug in chord. Found a
     corruption in memory, still dont find the bug
** 17-18 [100%]
   - [X] Analyze stacks, the bug has its origins on the SR benchmarks


** 21 [100%]
   - [X] Using gdb. Found where the SIGSEV comes from: raw_swapcontext
     from suspend_serial of smx_context_raw.c. The problem is with the
     address of the next_context The problem seems to be with the way
     'i' index was computed in smx_ctx_raw_suspend_serial. I fixed it
     and now it works.
** 22 [100%]
   - [X] Found 2 more segfaults: when nthreads=1 using the SR
     benchmarks, and when the sizes are too big (with or without
     benchmarks) in chord simulation.
   - [X] Re run experiments with SR with smaller sizes, in the cluster
** 23 [100%] 
   - [X] found that the 'performance fix' might be what causes the
     segfaults in some scenarios
** 24 [100%]
   - [X] Fixed potential SIGSEV when removing communication action
     when a SURF communication action is finishes (SIMIX_post_comm)
** 25 [100%]
   - [X] Make new experiments with bigger sizes: speedup (amdahl,
     /log_amdahl), SR (/log_sr), and raw (/log)(to compare
     intrusiveness of experiment). Use parapluie
   - [X] Prepare "micro" amdahl timings. That would be I)c). Use SR
     experiment, one with 1 thread (seq), one with better parallel
     version. Average timings of each amount of processes and then
     calculate speedup of each amount of processes


** 28 [100%]
   - [X] run SR like this: adding all the times of the parallel
     execution; taking the maxtime of the parallel execution. That way
     I get the sequential time of each SR, and the parallel time.
   - [X] generate 300000, 1000000 nodes files again, there are some
     problems with the current ones. Run final part of experiments
     with it(raw, amdahl, sr)
   - [X] Migrate from Rstudio to emacs
** 29 [100%]
   - [X] Work on better plots in rstudio. Work on report
** 30 [100%]
   - [X] fix SR
   - [X] keep working with report
** 31 [100%]
   - [X] organize data of experiments. Check that I have everything
     and probably relaunch some exp. to update data with the fixed
     version of SimGrid

* August
** 1 [100%]
   - [X] work on benchmark not intrusive
** 4 [100%]
   - [X] make new speedup plot with the bigger sizes (already got the
     logs). with 2,4,8,16,24 threads
   - [X] put numbers below bars in sr-distribution
** 5 [100%]
   - [X] get new data and make a decent sr-times plot,
   - [X] make sr-par-threshold with dots and add smooth line.
** 6 [100%]
   - [X] Start with optimizations of parmap.
** 7 [100%]
   - [X] Finish with binding cores details.
   - [X] Do some benchmarks with that.
   - [X] Write section in report, plot a graph
** 8 [100%]
   - [X] Check cache misses of previous/optimized version with perf.
   - [X] Start with parmap between N cores.
** 11 [100%]
   - [X] find why I get a deadlock running chord -> commit
     b533e2f7a6f6ebf750a96243804688169d2e6d9e, change only the
     #define. Also, check that the code at SIMIX_post_comm is deleted.
** 12 [100%]
   - [X] Still have some random deadlocks at the end of the
     simulation.Random. have to do some pinpoint, beginning from the
     performance fix.
** 13 [100%]
   - [X] Fix deadlock: delete SIMIX_process_cleanup(smx_proc) from
     src/msg/msg_process.c, why is that there?
   - [X] Do timings with maestro sleep+(N-1)
 
** 14 [100%]
   - [X] Timings maestrosleeps + (N-1) with 100k, 300k
** 18 [100%]
   - [X] Put code of bindings in order.
   - [X] Exp. intrusiveness with 3k, 5k, 10k, 25k, 50k, 75k nodes. (in
     progress)
** 19 [100%]
   - [X] Work with ideas of adaptative algorithm. Do some meditions if
     have time.
   - [X] Tons of meditions and benchmarks of parmap opt.,
     intrusiveness, amdahl speedup.

** 20 [100%]
   - [X] Amdahl speedup with 300k, 500k
   - [X] Short tests with adaptive algorithm in cluster.
   - [X] graph to show times of parmapN, parmapN-1 and original (al)
   - [X] Polish some things in report, like the plots with newer data,
     and some numbers using that data.
** 21 [100%]
   - [X] Write down things about binding threads.
   - [X] Run a new benchmark with the adaptive algorithm
** 22 [100%]
   - [X] Significant improve on adaptive algorithm plot. Write
     conclusions of this.
   - [X] Run remaining Amdahl experiments.
** 25 [100%]
   - [X] Finally, got a nicer dataset/plot of sr-par-threshold.
   - [X] Start Busy Waiters exp.
** 26 [100%]
   - [X] Constant vs. Precise with sr-par-threshold plot.(use a node
     or something, this TAKES time)
   - [X] Keep w/busy waiters optimization.
   - [X] Amdahl: Do plot with data gathered
** 27 [100%]
   - [X] Make more Constant mode experiments with sr-speedup to get
     better shape in plot
   - [X] plot busy_waiters vs. futex,check if there is some
     improvement.
   - [X] Use node to process the data of sr-counts
** 28 [100%]
   - [X] Process tables of sr-times plot and save them to generate
     latex faster.
   - [X] Work on report (organize plots, sections)

** 29 [100%]
   - [X] General cleanup of repository: erase old folders, update
     scripts, organize everything.
   - [X] Add documentation to scripts.

* September
** 1 [100%]
   - [X] comments about how to regenerate data in report.
   - [X] Re-run busy-waiters. Re-run speedup of scheduling rounds.

** 2 [100%]
   - [X] Integrate Luka script with mine. Make it more portable.
   - [X] Work on sr-par-threshold (plot again with new data, compare
     to old plot. Plot only with specific settings: certain amount of
     threads and sizes)
** 3 [100%]
   - [X] transforms files to csv.
   - [X] cleanup R code.
   - [X] modify logs paths in report. Add code to Data Analysis
     section.
** 4 [100%]
   - [X] Recheck plots, redo the sr-times, sr-par-thresh, busy
   - [X] new sr-distribution plot
** 5 [100%]
   - [X] Fix bugs of sr-distribution R code

** 8 [100%]
   - [X] add units/labels to plots. Add conclusions to plots.
   - [X] Take uniform distribution of sizes (not choose them
     randomly. Not choose 1000, 5000, 10000. Choose them equally
     distributed).
   - [X] Put host info in each chord_100*
   - [X] Change scripts to generate .csv, not tables.
** 9 [100%]
   - [X] test remote emacs, examples 
   - [X] test new benchmark with SR experiment
** 10 [100%]
   - [X] R remote execution + emacs, working fine
   - [X] G5K: create an image to accelerate a node setup. Check proxy
     configuration and set keys to clone SimGrid+report.
** 11 [100%]
  - [X] Work on portability&reproducibility of report. Rename/cleanup
    logs folders in a proper way.
  - [X] get_times.py now more general (can gather amdahl times,
    usr+sys, elapsed)
** 12 [100%]
  - [X] Make image of kadeploy better (add .vimrc, proxy settings,
    make setup.sh file and add it)
  - [X] Write about busy waiters comparison
  - [X] aesthetics of report.org

** 15 [100%]
  - [X] Make plots in same column of the same size (R)
** 16 [100%]
CUANDO SE AUMENTAN LOS THREADS AUMENTAN LAS SCHEDULING ROUNDS, POR???
  - [X] Integrate sr-distribution in the produced .pdf
  - [X] Drop everything related to the constant model. Precise mode
    needs to become more efficient.
  - [X] Ensure that every graph has a caption, a legend if it presents
    more than one curve, and that the axis are explained.
  - [X] Finish experiments of Amdahl with 1m nodes.(Precise mode)

** 17 [100%]
   - [X] Add setup scripts to report.
   - [X] launch experiments for speedup, with a more uniform
     distribution of sizes
** 18 [100%]
  - [X] Integrate testall script, scripts to generate
    platforms/deployment files to report
  - [X] Keep with standar benchmark in g5k

** 19 [100%]
  - [X] Delete get_sr_counts.py. The same thing can be achieved with oneline bash script.
  - [X] Add the used algorithm in section 5.2.
  - [X] Sizes, threads and log_folder should be defined in a separate
    block of code and then use them trhoughout the file in the same sh
    session

** 22 [12%]
  - [X] Improve algorithm. Describe variables, better names, erase
    timers
  - [ ] Absolute numbers in section 3.1 (current speedup) and 5.2
    (Adaptive algorithm). Write something + maybe a table with
    absolute times +  memory consumption.
  - [ ] Figure 1:
    - be actually run with SimGrid v3.11 maybe (not sure)
    - have more data (In Progress)
    - report also the memory consumption (Peak and average memory
      already measured)
    - report some absolute numbers here (Figure 1), maybe on another
      graph so that we can see the time that it actually takes.
    - Make the speedup chart and also the amdahl one. Or put those
      two in the same graph

  - Compare sequential time of 3.11 against newer version too.
  - https://github.com/mquinson/simgrid-simpar/issues 
Experiments:
  - [ ] Improve benchmark of SR's & make new SR exp with normal
    benchmark and uniform distributed sizes. With this data, replot
    corresponding graphs.
  - [ ] Figure 4. Use more data.
  - [ ] See how the adaptative threshold evolved over a given
    simulation. Maybe do a graph where the simulated time (the
    differing SRs) are given in abscisse and the adaptative threshold
    computed at that point is given in ordinate. And maybe use several
    curves on that graph, for several sizes of simulation.

Other things:
  - Run benchmarks with other examples.
  - Check uniformity of nodes amounts on some experiments.
  - Improve adaptive algorithm.

Long term tasks:
  - Run chord with 1m nodes. (In progress)
  - Run chord with 2m nodes.

* Useful info:
** List of recommended packages/software to run experiments
   - Emacs24
   - org-mode8.2
   - ess
   - R
   - texlive
   - cmake make gcc git libboost-dev libgct++ libpcre3-dev linux-tools
     gdb liblua5.1-0-dev libdwarf-dev libunwind7-dev valgrind
     libsigc++
** To deploy a node with a personalized image
   1) oarsub -p 'cluster="parapluie"' -l nodes=1,walltime=8:00 -I -t deploy
   2) kadeploy3 -f $OAR_NODEFILE -e debian-simgrid -k
   3) connect to the deployed node and run ./post_deploy.sh
   4) ssh-keygen, put .pub in authorized_keys of rennes frontend
   5) R packages and libraries needed should be installed.

** To run classical chord experiment
   - Steps to connect to G5K and deploy SimGrid:
     1) connect to G5k, connect to Rennes, try to ask a parapluie node:
       oarsub -p "cluster='parapluie'" -l nodes=5,walltime=2 -I -t deploy
	Aks for an specific node, for example:
       oarsub -p 'cluster="parapide"' -l {'network_address in ("parapide-8.rennes.grid5000.fr")'}/nodes=1,walltime=5:00 -I -t deploy
     2) apt-get update && apt-get install cmake make gcc git libboost-dev libgct++ libpcre3-dev linux-tools gdb liblua5.1-0-dev libdwarf-dev libunwind7-dev valgrind libsigc++
     3) copy simgrid from Rennes frontend
     4) cmake -Denable_compile_optimizations=ON -Denable_supernovae=OFF -Denable_compile_warnings=OFF -Denable_debug=OFF -Denable_gtnets=OFF -Denable_jedule=OFF -Denable_latency_bound_tracking=OFF -Denable_lua=OFF -Denable_model-checking=OFF -Denable_smpi=OFF -Denable_tracing=OFF -Denable_documentation=OFF .
     5) make && make install && sudo chmod 777 /usr/local/lib/libsimgrid.so.<version_number>
     6) example run:
        ./chord One_cluster_nobb_1000_hosts.xml chord1000.xml --log=root.thres:critical --cfg=contexts/stack_size:16 --cfg=contexts/guard_size:0 --cfg=network/model:Constant --cfg=network/latency_factor:0.1
	./chord One_cluster_nobb_10000_hosts.xml chord10000.xml --cfg=contexts/stack_size:16 --log=root.thres:critical --cfg=network/model:Constant --cfg=network/latency_factor:0.1 --cfg=contexts/nthreads:4
	./chord One_cluster_nobb_10000_hosts.xml chord10000.xml --cfg=contexts/stack_size:16 --log=root.thres:critical --cfg=maxmin/precision:0.00001 --cfg=contexts/nthreads:4 --cfg=maxmin/precision:0.00001
     7) to run test, this should work:  ./testall.sh path/to/simgrid/ 3.11
     8) Dont forget to modify script to copy logs to home folder (otherwise they will lay on the node, and they will be erased)
     9) To copy something from rennes to the deployed node: scp -r rtortilopez@rennes.grid5000.fr:path/to/file . 
   - To print current revision hash git rev-parse --short HEAD
     1) git log --pretty=oneline --pretty=format:"%h %s"  --since 17/11/2013 --until 23/01/2014 |  less
     2) If it fails to allocate stack with big amount of nodes, then use --cfg=contexts/guard_size:0

for file in sr_*; do tail -n +0 $file >> sr_total_1000.log; done
** Profilers:
    1) perf record ./chord ...
    2) perf record -g -e cpu-clock ./chord and then:
    3) perf script | stackcollapse-perf.pl | flamegraph.pl > myapp.svg
    4) script gdb poorman profiler of Gabriel | stackcollapse-gdb.pl | flamegraph.pl > myapp.svg . Example:
       Run chord:
       ./chord One_cluster_nobb_10000_hosts.xml chord10000.xml --log=root.thres:critical --cfg=contexts/stack_size:16 --cfg=network/model:Constant --cfg=network/latency_factor:0.1 &
       and: 
       ./poorman.sh 1000 0.1 $(pidof chord) | ./stackcollapse-gdb.pl | ./flamegraph.pl > myapp.svg
    5) To copy from node to laptop: scp root@<node_number>.rennes.grid:~/SimGrid/examples/msg/chord/myapp.svg .
    6) poor man's profiler
    7) try with compilation flag -fno-omit-frame-pointer
** To run SG-PRT (Performance regression test):
repository: git+ssh://rtortilo@scm.gforge.inria.fr//gitroot/simgrid/simgrid-perf-reg-tests.git
1) set up a node somewhere.
2) apt-get update && apt-get install cmake make gcc git libboost-dev libgct++ libpcre3-dev linux-tools gdb r-base ruby gem . If possible, gem install rserve-client
3) To install libraries of R, use script download_r_packages.sh
4) Start Rserve daemon in R (library(Rserve); Rserve())
5) set number of commits wanted to analyze in SG-PRT.rb
6) ./SG-PRT.rb

** Pinpoint tests
1) To get a list of specific commits (and count them,etc):
   git log 772d63c..ce1289d --pretty=oneline | head -n570 | less
2) If compilaton of chord fails for version 3.10 (or whatever else),
   try copying the content of folder src/ to usr/local/src
** Useful commands
- To rename bunch of files (useful for organizing logs):
  rename 's/^/2_/' sr_5000_threads*
  (basically rename <pattern_prefix>  <pattern_group_files>)
* Paper
** Problem Analysis
  1) Optimal threshold for Amdhal. Which portion of the problem is
     paralellizable. Which not. Why is hard?(a) Two graphics: #SD
     vs. #process (b) && #SD vs. time(SD) (c)
     
** Find threshold between sequential/parallel
  1) test over real runs. not simulations
  2) geometric mean (of..)
Once I get the basis threshold:
  3) adaptative algorithm to choose how many threads wake up in each round:
     This is what is already done (smx_ctx_*_runall):
        * if #proc<threshold  --> sequential
        * elif #proc>threshold  --> parallel
     Change threshold dinamically:
     There are timers already defined in the code, but they are not used to do this:
     * if #proc<thresh -->  sequential exec. (chrono) and then seq_time += chrono; seq_amount += #proc;
     * else ------------->  parallel exec. (crhono) and then par_time+=chrono; par_amount+=#proc;
     After 5 sched round:
                (a)                     (b)
     * if seq_time/seq_amount > par_time/par_amount THEN --thresh (c - coeff x a/b)
     * else ++thres
  4) parallel threshold of parmap in cache?
  5) Fast Init: save threshold on disk?

Versions of SimGrid:
SimGrid3.11.1 e32a2a561ef184dc9ef8cdaf25759bba6b2ea198
SimGrid3.8    71c9241aa27344f9f8f02f3c1272af4556691713
SimGrid3.9    f95108e7e5bcb66bba76a24c1c433eee710e38e0
SimGrid3.10   772d63cca583f5d16096fa9f487b4ab07d9af8f0

** Optimizations
  1) bind each tread to one core [X]
  2) implement parmap between N cores: maestroawake+(N-1)(default); [X]
                                       The key for the next 2 optimizations relies on finding how to sleep master,
                                       the rest involves only creating N threads or N-1 threads:
                                           maestrosleep+(N)
                                           maestro sleep+(N-1)
  3) parmap next. Not now.
  4) busy waiters with different #proc. (1-5 --> sequential; 6-20 --> 4busy waiters; 20-inf --> 16 busy waiter).[X]
  Performance regression testing
  
** Hot topics task 5
1) we are near amdhal paralelism threshold, because there are no more
   things to paralellize.
2) we want to run in parallel not only the threads but also the events
   in each thread?
3) we want to find the independent events and run them in parallel.


